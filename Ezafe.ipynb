{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chemical-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wicked-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/marjan/Desktop/project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "religious-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADJ_ADV_intersection(adjs: pd.DataFrame, advs: pd.DataFrame) -> pd.DataFrame:\n",
    "    df1 = adjs[adjs['word'].isin(advs['word'])]\n",
    "    df2 = advs[advs['word'].isin(adjs['word'])]\n",
    "    \n",
    "    df = pd.concat([df1, df2])\n",
    "    df = df[['word', 'tag', 'adj_count', 'adv_count', 'sent', 'source', 'src_sent_count', 'src_word_count']]\n",
    "    df = df.sort_values(by= ['word', 'tag'])\n",
    "\n",
    "    for token in df2.word.unique():\n",
    "        df.loc[df['word'] == token, 'adj_count'] = len(df1[df1['word'] == token])\n",
    "        df.loc[df['word'] == token, 'adv_count'] = len(df2[df2['word'] == token])\n",
    "\n",
    "    df['adj_count'] = df['adj_count'].astype(int)\n",
    "    df['adv_count'] = df['adv_count'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boolean-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(lst: List[Tuple[str, str]], sent_count: int, word_count: int, category='adj', threshold=1) -> pd.DataFrame:\n",
    "    count = category + '_count'\n",
    "\n",
    "    df = pd.DataFrame(lst, columns =['word', 'sent'])\n",
    "    df = df.drop_duplicates()\n",
    "    df.insert(0, count, 0)\n",
    "    df['tag'] = category\n",
    "    df['source'] = 'UD'\n",
    "    df['src_sent_count'] = sent_count\n",
    "    df['src_word_count'] = word_count\n",
    "\n",
    "    for token in df['word'].unique():\n",
    "        df.loc[df['word'] == token, count] = len(df[df['word'] == token])\n",
    "        \n",
    "    df = df[df[count] >= threshold].sort_values(by= [count], ascending=False)\n",
    "    \n",
    "    return df[['word', count, 'tag', 'sent', 'source', 'src_sent_count', 'src_word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nominated-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_UD_data(dirs: List[str], adj_tags=['ADJ'], adv_tags= ['ADV']) -> (List[Tuple[str, str]], List[Tuple[str, str]]):\n",
    "    ADJs = []\n",
    "    ADVs = []\n",
    "    tagset = []\n",
    "    text = []\n",
    "    sent_counter = 0\n",
    "    word_counter = 0\n",
    "    for file_name in dirs:\n",
    "        with open(file_name) as file:\n",
    "            lines = file.readlines() \n",
    "            for i, line in enumerate(lines):\n",
    "                line = line.split()\n",
    "                if line and i > 0:\n",
    "                    if line[0] == '#' and line[1] == 'text':\n",
    "                        text = line[3:]\n",
    "                        sent_counter += 1\n",
    "\n",
    "                    if line[0].isdigit():\n",
    "                        token = line[1]\n",
    "                        tag = line[3]\n",
    "                        tagset += [tag]\n",
    "                        word_counter += 1\n",
    "\n",
    "                        if tag in adj_tags:\n",
    "                            ADJs += [(token, ' '.join(text))]\n",
    "                        elif tag in adv_tags:\n",
    "                            ADVs += [(token, ' '.join(text))]\n",
    "                        \n",
    "    print('tagset:', sorted(set(tagset)))\n",
    "    print('number of words:', word_counter)\n",
    "    print('number of sentences:', sent_counter)\n",
    "            \n",
    "    return ADJs, ADVs, sent_counter, word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stone-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_paths(files: List[str], root= root_dir, lang_dir= 'PER_files') -> List[str]:\n",
    "    lst = []\n",
    "    directory = os.path.join(root, 'data', lang_dir)\n",
    "    for name in files:\n",
    "        lst.append(os.path.join(directory, name))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "neither-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input directiries for Persian\n",
    "Persian_file_names = ['fa_perdt-ud-dev.conllu',\n",
    "                 'fa_seraji-ud-train.conllu', 'fa_seraji-ud-test.conllu', 'fa_seraji-ud-dev.conllu']\n",
    "PERfile_paths = input_paths(Persian_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "south-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directories for Persian\n",
    "persian_adj_dir = os.path.join(root_dir, 'output', 'Persian', 'persian_adjs.csv')\n",
    "persian_adv_dir = os.path.join(root_dir, 'output', 'Persian', 'persian_advs.csv')\n",
    "persian_intersection_dir = os.path.join(root_dir, 'output', 'Persian', 'persian_inter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effective-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input directiries for Enlglish\n",
    "English_file_names = ['en_partut-ud-dev.conllu', 'en_partut-ud-train.conllu', 'en_partut-ud-test.conllu', \n",
    "                 'en_pud-ud-test.conllu', 'en_lines-ud-dev.conllu', 'en_lines-ud-train.conllu', 'en_lines-ud-test.conllu']\n",
    "ENGfile_paths = input_paths(English_file_names, lang_dir='ENG_files' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "whole-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directories for English\n",
    "English_adj_dir = os.path.join(root_dir, 'output', 'English', 'English_adjs.csv')\n",
    "English_adv_dir = os.path.join(root_dir, 'output', 'English', 'English_advs.csv')\n",
    "English_intersection_dir = os.path.join(root_dir, 'output', 'English', 'English_inter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "victorian-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagset: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'VERB', 'X']\n",
      "number of words: 178067\n",
      "number of sentences: 7453\n"
     ]
    }
   ],
   "source": [
    "persian_adjs, persian_advs, pers_sent_count, pers_word_count = get_UD_data(PERfile_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "single-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagset: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
      "number of words: 165027\n",
      "number of sentences: 8333\n"
     ]
    }
   ],
   "source": [
    "english_adjs, english_advs, eng_sent_count, eng_word_count = get_UD_data(ENGfile_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "talented-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_adj_df = create_df(persian_adjs, pers_sent_count, pers_word_count, threshold=4)[:3333]\n",
    "persian_adv_df = create_df(persian_advs, pers_sent_count, pers_word_count, category='adv', threshold=4)[:3333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interpreted-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['پس', 'چه', 'بعد', 'پیش', 'خیلی', 'هیچ', 'حتی', 'بسیار', 'نه',\n",
       "       'البته', 'مثل', 'چرا', 'چنین', 'فقط', 'حالا', 'تنها', 'هم', 'هنوز',\n",
       "       'امروز', 'قبل', 'شاید', 'دیگر', 'همچنان', 'اکنون', 'کنون', 'چنان',\n",
       "       'بالا', 'اینجا', 'آنجا', 'نیز', 'مثلا', 'همیشه', 'غیر', 'دیروز',\n",
       "       'دور', 'مانند', 'چگونه', 'سپس', 'بیرون', 'چی', 'متأسفانه', 'امسال',\n",
       "       'نزدیک', 'هرگز', 'اصلا', 'هنگام', 'الان', 'نظیر', 'حداقل',\n",
       "       'اخیراً', 'خوب', 'کاملاً', 'کمی', 'چون', 'همچون', 'همواره', 'کجا',\n",
       "       'معمولاً', 'گاهی', 'هرچه', 'بویژه', 'واقعاً', 'هم\\u200cاکنون',\n",
       "       'اتفاقا', 'مگر', 'چقدر', 'صرفاً', 'همزمان', 'قبلاً', 'سرانجام',\n",
       "       'حال', 'روزانه', 'دوباره', 'به\\u200cخوبی', 'به\\u200cشدت',\n",
       "       'احتمالاً', 'گویی', 'ظاهراً', 'بشدت', 'واقعا', 'قطعاً',\n",
       "       'خوشبختانه', 'ناگهان', 'آخر', 'حتماً', 'نه\\u200cتنها',\n",
       "       'به\\u200cزودی', 'به\\u200cتدریج', 'هیچگاه', 'عملاً', 'دقیقاً',\n",
       "       'تقریباً', 'اینک'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persian_adv_df['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "victorian-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_adj_df = create_df(english_adjs, eng_sent_count, eng_word_count, threshold=4)[:3333]\n",
    "english_adv_df = create_df(english_advs, eng_sent_count, eng_word_count, category='adv', threshold=4)[:3333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "occupied-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['out', 'also', 'up', 'so', 'more', 'only', 'now', 'very', 'then',\n",
       "       'back', 'just', 'as', 'too', 'there', 'again', 'where', 'down',\n",
       "       'how', 'well', 'even', 'still', 'here', 'never', 'off', 'at',\n",
       "       'most', 'on', 'already', 'always'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_adv_df['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "found-legislature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3767                                                                                                                                                                                                               Perhaps my father was a treasure chest because he seemed to be able to lay up for himself inexhaustible riches.\n",
       "5542                                                                                                                                                                                                                    You know yourself that the agreement with South Africa was held up because of the fisheries question, too.\n",
       "4532                                                                                                                                                                                                                    Shrugging, he gives up and I turn to the twice disagreeable chicken and eat guiltily, my appetite spoiled.\n",
       "3945    Each time he took a walk, he felt as though he were leaving himself behind, and by giving himself up to the movement of the streets, by reducing himself to a seeing eye, he was able to escape the obligation to think, and this, more than anything else, brought him a measure of peace, a salutatory emptiness within.\n",
       "835                                                                                                                                                                 and the extension of the content of the technical and operational back-up to administrative support for active investigations, with intermediation by Europol.\n",
       "                                                                                                                                                                   ...                                                                                                                                                            \n",
       "4157                                                                                                                                                                                                        Having completed this operation, he would return the notebook to his pocket, pick up his bag, and continue on his way.\n",
       "4679                                                                                Within five hours John had repaired the engines, but the port officials claimed that the ship was incapacitated and demanded that the captain post a twenty-thousand-dollar bond against expenses that might be run up by his \"crippled ship.\"\n",
       "6491                                                                                                                                                                                                                    He had emerged into a dingy alleyway that seemed to be made up entirely of shops devoted to the Dark Arts.\n",
       "6313                                                                                                                                                                                                            If the Dursleys wake up, I'm dead, said Harry as he tied the rope tightly around a bar and Fred revved up the car.\n",
       "4029                                                                                                                                                                                                                                                                         The apartment loomed up around him as a kind of blur.\n",
       "Name: sent, Length: 206, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with pharasal verbs ['out', 'up', 'back', 'down', 'off', 'at', 'on']\n",
    "english_adv_df[english_adv_df['word'] == 'up']['sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "prescribed-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3976    Nevertheless, as time wore on he found himself...\n",
       "5224    I flung out of his hut (he lived all alone in ...\n",
       "5185    Such a suspicion made one pause – for out ther...\n",
       "7460                               So we try it out here.\n",
       "5176    He had served three terms of three years out t...\n",
       "                              ...                        \n",
       "4438    At last he called the operator and asked wheth...\n",
       "7698        Shaking, Harry let Dobby out of the wardrobe.\n",
       "4475    Visibility in the queue is poor because of the...\n",
       "4451    In the top of the third St. Louis scored on a ...\n",
       "7867    We cooked breakfast in the remains of the fryi...\n",
       "Name: sent, Length: 222, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_adv_df[english_adv_df['word'] == 'out']['sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "furnished-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "associate-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>tag</th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>src_sent_count</th>\n",
       "      <th>src_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>پیدا</td>\n",
       "      <td>112</td>\n",
       "      <td>adj</td>\n",
       "      <td>پیداست که این‌ها نفوذیند؛ این‌ها جزو آن دسته‌ی...</td>\n",
       "      <td>UD</td>\n",
       "      <td>7453</td>\n",
       "      <td>178067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>پیدا</td>\n",
       "      <td>112</td>\n",
       "      <td>adj</td>\n",
       "      <td>وی تأکید کرد: اکتفا به حمایت از فرمایشات ایشان...</td>\n",
       "      <td>UD</td>\n",
       "      <td>7453</td>\n",
       "      <td>178067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>پیدا</td>\n",
       "      <td>112</td>\n",
       "      <td>adj</td>\n",
       "      <td>بعد از این که سریال را به من پیشنهاد دادند که ...</td>\n",
       "      <td>UD</td>\n",
       "      <td>7453</td>\n",
       "      <td>178067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  adj_count  tag  \\\n",
       "8637   پیدا        112  adj   \n",
       "10878  پیدا        112  adj   \n",
       "3022   پیدا        112  adj   \n",
       "\n",
       "                                                    sent source  \\\n",
       "8637   پیداست که این‌ها نفوذیند؛ این‌ها جزو آن دسته‌ی...     UD   \n",
       "10878  وی تأکید کرد: اکتفا به حمایت از فرمایشات ایشان...     UD   \n",
       "3022   بعد از این که سریال را به من پیشنهاد دادند که ...     UD   \n",
       "\n",
       "       src_sent_count  src_word_count  \n",
       "8637             7453          178067  \n",
       "10878            7453          178067  \n",
       "3022             7453          178067  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persian_adj_df[persian_adj_df['word'] == 'پیدا'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "permanent-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_intersection = ADJ_ADV_intersection(persian_adj_df, persian_adv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "viral-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['خوب', 'دیگر'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persian_intersection['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "facial-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_intersection = ADJ_ADV_intersection(english_adj_df, english_adv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "flush-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['more'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_intersection['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "editorial-bunny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>src_sent_count</th>\n",
       "      <th>src_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, tag, adj_count, adv_count, sent, source, src_sent_count, src_word_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_intersection[(english_intersection['word'] == 'very') & (english_intersection['tag'] == 'adj')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abstract-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050405040504050404"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persian adj_adv_intersection to adv ratio:\n",
    "len(persian_intersection) / (len(persian_adj_df) + len(persian_adv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funny-usage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03660366036603661"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_intersection) / (len(english_adj_df) + len(english_adv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "infectious-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_adj_df.to_csv(persian_adj_dir)\n",
    "persian_adv_df.to_csv(persian_adv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "impossible-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_intersection.to_csv(persian_intersection_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
